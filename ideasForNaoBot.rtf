{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww17700\viewh14280\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx4850\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\b\fs28 \cf0 PROJECT: 
\b0 THE TEACHER ASSISTANT
\b \

\b0 \'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\

\b Descripton:\

\b0 - Der Roboter wird zur Unterst\'fctzung f\'fcr einen Lehrer / Professor / Tutor eingesetzt\
- Zur Steuerung des Bots wird \'93Python Speech Recognition\'94 eingesetzt. \
- Es gibt spezifische Kommandos.\
  -> Kommandoliste.: 		\
	\'93Begr\'fc\'dfe Personen im Raum\'94 						-> Initialising()\
	\'93Die Pr\'fcfung beginnt\'94 								-> examMode()\
	\'93Schmei\'dfe bestimmte Person aus dem Raum\'94 	-> throwOut()\
\
[
\b Initialising
\b0 ]\
case1: Person unbekannt\
	- Nao nimmt mehrere Fotos auf\
	- Fragt die person nach ihrem namen\
	- speichert Foto und Name als Tupel ab\
	- Nao bedankt sich und begr\'fc\'dft die Person\
\
case2: Person ist bekannt\
	- Nao erkennt die Person\
	- Es werden zus\'e4tzliche Fotos gespeichert (Erkennung wird verbessert)	- Person wird mit ihrem Namen begr\'fc\'dft\
	\
case3: Person ist bekannt wird aber nicht oder nur ungen\'fcgend erkannt\
	- Nao fragt bist du Person X\
	- Falls ja, werden zus\'e4tzliche Fotos gespeichert (Erkennung wird verbessert)\
	- Falls nein, neue Person wird gespeichert (case1)\
\
\
[
\b examMode()
\b0 ]\
Case 1 : Everything is silent , robot keeps roaming around\
Case 2 : Nao recognises voice , he tracks the source\
               Nao checks if the person has previous warnings\
\
		Case 2a :\
		Person has no previous warnings , Nao gives him a warning\
		Case 2b:\
		Person has a previous warning , triggers throwOut Module , \
		where it takes the student outside of the exam hall\
\
[
\b throwOut()
\b0 ]\
Two types of triggers :\
- Throw out via Voice command \
- Triggered after 2nd warning in Exam Mode \
-> Ask the student to follow him to the door, Thanks the student , see you next semester \
\
\
\
\
\
\
\
######################################\
/// TheAppBot (1)\
-> Control App: Using the camera for visualisation and the App for controlling the bot\
\
\
/// Optical Character Recognition (OCR) (4)\
-> Read a paper out loud\
\
########################################\
\
/// Unknown environment Bot\
-> Recognise unknown environment\
-> Able to walk in e.g. forest\
\
/// Referee-Bot\
-> Recognizing Goal, Offside, Out of Bound\
\
\
\
\
\
/// Greeting-Agent (I)  \{Empfangsdame\}\
-> Suche nach einer bestimmten Markierung\
	: bspw. neonfarbenes Band am Hosenbein\
-> Gehe hin und mach zuf\'e4llige Posture\
	: \
-> M\'f6gl. Probleme\
	: Person nicht im Raum\
	: Person verl\'e4sst den Raum\
	: Erkennt keine Markierung\
	: Kann nur bestimmte Personen begr\'fc\'dfen\
\
/// Alexa integration (II)\
-> Listening to commands\
	:1 Cmd - Starten der Demo\
	:2 Cmd - Begr\'fc\'dfe Person X mit X:= Farbe des Fu\'dfgelenk-Bandes\
	:3 Cmd - Schmei\'dfe Person X aus dem Raum\
	:4 Cmd - Verabschiede die Gesellschaft\
\
\
\
Detaillierter Ablauf:\
-> Start der Demonstration\
	- Roboter befindet sich in einem Raum (mit Personen)\
	- per Sprachsteuerung wird dem Roboter gesagt: \'93Begr\'fc\'dfe alle Personen\'94\
	\
-> Initialisierung (\'93Begr\'fc\'dfe alle Person\'94):\
	- Falls sich Personen im Raum befinden, benutzt er FaceID um die Personen zu erkennen\
	- Er geht zu jeder erkannten Person, begr\'fc\'dft dieses und fragt nach dem Namen\
	- FaceID und Namen werden als Tupel gespeichert\
}